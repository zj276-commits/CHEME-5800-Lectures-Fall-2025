{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6f6388-ace0-4bc1-a58c-bc1470936d88",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Example: Properties of Markov Models and Stationary Distributions\n",
    "In this example, you will explore the fundamental properties of Markov models by constructing a discrete-time Markov chain, computing its stationary distribution, and validating the theoretical predictions through simulation.\n",
    "\n",
    "> __Learning Objectives:__\n",
    ">\n",
    "> After completing this activity, students will be able to:\n",
    "> * **Construct and validate transition matrices:** We build a three-state Markov chain transition matrix and verify that it satisfies the row-stochastic property, where each row sums to one and represents valid transition probabilities.\n",
    "> * **Compute stationary distributions through iteration:** We implement iterative methods to compute the stationary distribution π by raising the transition matrix to successive powers until convergence and verify the rank-one property of the resulting matrix.\n",
    "> * **Simulate Markov chain dynamics and validate convergence:** We generate state sequences by sampling from categorical distributions based on transition probabilities and demonstrate that the empirical state frequencies converge to the theoretical stationary distribution as the number of samples increases.\n",
    "\n",
    "This is an essential foundation for understanding stochastic processes in machine learning and data science. So, let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e972a9-2b8c-4982-9828-b573467e571b",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "First, we set up the computational environment by including the `Include.jl` file and loading any needed resources.\n",
    "\n",
    "> The [`include(...)` command](https://docs.julialang.org/en/v1/base/base/#include) evaluates the contents of the input source file, `Include.jl`, in the notebook's global scope. The `Include.jl` file sets paths, loads required external packages, etc. For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). \n",
    "\n",
    "Let's set up our code environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d638f1eb-54e7-4c80-bd59-bd85e02af8f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"Include.jl\")); # include the Include.jl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61c17f",
   "metadata": {},
   "source": [
    "In addition to standard Julia libraries, we'll also use [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). Check out [the documentation](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/) for more information on the functions, types, and data used in this material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99efe4-8b7d-4197-9168-ecd0ce9b0ccd",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Before we start this example, let's set up the `iterate(...)` method and specify some constants. We'll use the `iterate(...)` method to compute the stationary distribution $\\pi$.\n",
    "```julia\n",
    "iterate(P::Array{Float64,2}, counter::Int; \n",
    "        maxcount::Int = 100, ϵ::Float64 = 0.1) -> Array{Float64,2}\n",
    "```\n",
    "> Iteratively computes a stationary distribution. Computation stops if ||P_new - P|| < ϵ or the max number of iterations is hit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295be0ce-0194-4408-8bb0-51bd667ec3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function iterate(P::Array{Float64,2}; \n",
    "        maxcount::Int = 100, ϵ::Float64 = 0.1)::Array{Float64,2}\n",
    "\n",
    "    # initialize -\n",
    "    counter = 1; # initialize the iteration counter\n",
    "    is_ok_to_stop = false; # flag for while loop\n",
    "    P_new = nothing; # initialize P_new matrix\n",
    "    N = size(P,1); # number of rows in P matrix\n",
    "    πₒ = ones(Float64, N) ./ N; # initial uniform distribution\n",
    "    π = reshape(πₒ, 1, N); # initialize π (make it a 1 x N matrix)\n",
    "    \n",
    "    # main loop - iterate until the difference ||P_new - P|| <= ϵ -or- we run out of iterations\n",
    "    while (is_ok_to_stop == false)\n",
    "\n",
    "        π′ = π * P; # update π\n",
    "        if (norm((π′ - π),1) <= ϵ || counter >= maxcount)\n",
    "            is_ok_to_stop = true; # set the flag to exit the while loop\n",
    "\n",
    "            # warn the user if we hit the maxcount\n",
    "            if (counter >= maxcount)\n",
    "                @warn \"Maximum iteration count reached before convergence.\"\n",
    "            end\n",
    "        end\n",
    "        π = reshape(π′, 1, N); # update π (make sure it's a 1 x N matrix)\n",
    "        counter += 1; # update the counter\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    return π;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916996a-d6fa-44dc-9749-654745ecc073",
   "metadata": {},
   "source": [
    "#### Constants\n",
    "In the simulations below, we'll need some constant values that we set here. In particular, we set a value for the `number_of_hidden_states` variable, the `number_of_simulation_steps` variable (the number of steps that we take in a Markov chain), and the `number_of_samples` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63086f21-0e27-4306-9e1a-6ba544eb6f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_hidden_states = 3; # how many states do we have?\n",
    "number_of_simulation_steps = 10000; # number of simulation steps\n",
    "number_of_samples = 10000; # number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3f880",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac0beb7",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <center>\n",
    "        <img src=\"figs/Fig-ThreeState-MM-Schematic.svg\" width=\"580\"/>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2bd82d-cf07-4204-98d2-6fedb456c3df",
   "metadata": {},
   "source": [
    "## Task 1: Set up the transition matrix for a three-state Markov model\n",
    "In this task, we'll set up the transition matrix $\\mathbf{P}$ for a three-state [Markov chain model](https://en.wikipedia.org/wiki/Markov_chain). In this example, we have three states $\\mathcal{S}=\\left\\{1,2,3\\right\\}$ where the probability of moving from state $i$ to state $j$ in the next time step, denoted as $p_{ij}$, are elements of the matrix $\\mathbf{P} \\in \\mathbb{R}^{3\\times{3}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0600f0f-977d-419f-992e-dbb0f9044bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = [\n",
    "    0.05 0.95 0.0 ; # moves for state 1\n",
    "    0.6 0.2 0.2 ; # moves for state 2\n",
    "    0.0 0.3 0.7 ; # moves for state 3\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47825d70",
   "metadata": {},
   "source": [
    "The rank of the transition matrix $\\mathbf{P}$ indicates the number of linearly independent rows (or columns). A full-rank matrix ensures that all states are reachable, which is important for guaranteeing the existence of a unique stationary distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa3b195-e388-4391-9fe5-5543a90af6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rank(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f76e3-9e30-4e92-bbfc-b24a1f646288",
   "metadata": {},
   "source": [
    "### Check: Do the rows of the transition matrix $\\mathbf{P}$ sum to `1`?\n",
    "We know that the rows of the transition matrix $\\mathbf{P}$ must sum to `1`, i.e., if we are in state $s_{i}\\in\\mathcal{S}$ at time $t$, then at time $t+1$ we must be in some state $s_{j}\\in\\mathcal{S}$. \n",
    "\n",
    "> __Check:__ Let's verify that the transition matrix $\\mathbf{P}$ meets this criterion using the [@assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert) by iterating over the rows of the transition matrix $\\mathbf{P}$ and checking the sum of each row. If any row does not meet this criterion, an [AssertionError](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError) will be thrown.\n",
    "\n",
    "So what do we see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b4a181-0930-4a1e-8349-250e9b015f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i ∈ 1:number_of_hidden_states\n",
    "    @assert sum(P[i,:]) == 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278e444",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d67b5-6857-43f9-8a1c-6cf8fc595221",
   "metadata": {},
   "source": [
    "## Task 2: Compute the stationary distribution $\\pi$\n",
    "In this task, we'll compute the stationary distribution $\\pi$ for our example [Markov chain](https://en.wikipedia.org/wiki/Markov_chain).\n",
    "For a non-periodic Markov chain with a finite state space $\\mathcal{S}$ and an invariant state transition matrix $\\mathbf{P}$,\n",
    "the state vector at time $j$, denoted by $\\mathbf{\\pi}_{j}$, has the property:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\sum_{j\\in\\mathcal{S}}\\pi_{sj} = 1\\qquad\\forall{s}\\in\\mathcal{S}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\pi_{sj}\\geq{0},\\forall{s}\\in\\mathcal{S}$. The state of the Markov chain at time step $n$, denoted by $\\mathbf{\\pi}_{n}$, is given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathbf{\\pi}_{n} = \\mathbf{\\pi}_{0}\\cdot\\left(\\mathbf{P}\\right)^n\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\mathbf{\\pi}_{n}$ is the state vector at time step $n$ and $\\left(\\mathbf{P}\\right)^n$ is the transition matrix raised to the $n$-th power. Finally, a unique stationary distribution $\\bar{\\pi}$ exists, where $\\mathbf{P}^{k}$ converges to a __rank-one__ matrix in which each row is the stationary distribution $\\pi$:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{k\\rightarrow\\infty} \\mathbf{P}^{k} = \\mathbf{1}^{\\top}\\otimes\\pi\n",
    "\\end{equation*} \n",
    "$$\n",
    "where $\\mathbf{1}$ is a column vector of all ones and the operator $\\otimes$ denotes a __Left Matrix Vector Product operation__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6518a5",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <center>\n",
    "        <img src=\"figs/Fig-Matrix-Vector-Left-bA-product-NeedToRedrawThis.png\" width=\"580\"/>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90d702-8b38-4569-ba5d-4c26b9f0450b",
   "metadata": {},
   "source": [
    "### Implementation details\n",
    "We'll compute the stationary distribution $\\bar{\\pi}$ using the iterative `iterate(...)` method. During each call to the `iterate(...)` method, using the pseudo code from the lecture notes.\n",
    "\n",
    "> __What is going to happen?__ \n",
    ">\n",
    "> We'll iterate until we hit one of two possible conditions:\n",
    "> * The `counter == maxcount`; at this point, the iteration stops, and the vector $\\bar{\\pi}$ is returned (but it may not be correct).\n",
    "> * The iteration also stops when the difference between subsequent estimates of $\\bar{\\pi}$ is smaller than a specified threshold $\\epsilon$. In this case, the correct $\\bar{\\pi}$ is returned.\n",
    "\n",
    "We'll save the stationary distribution in the $\\bar{\\pi}$ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae5bf7b7-7127-4738-ba90-bca8f745bca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "π = [0.3333333333333333 0.3333333333333333 0.3333333333333333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1×3 Matrix{Float64}:\n",
       " 0.274809  0.435115  0.290076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "π̄ = iterate(P, ϵ = 0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b813c-c988-4bc9-b1f5-a42c17c55c8a",
   "metadata": {},
   "source": [
    "### Check: Is the rank condition on the stationary distribution $\\bar{\\pi}$ correct?\n",
    "Once we reach the stationary distribution, the rank of the stationary distribution matrix $\\bar{\\pi}$ should be equal to `1`. Let's check whether this condition is true using the [@assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert). \n",
    "> __Check:__ If we do not meet this criterion, an [AssertionError](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError) will be thrown, and we should try using more iterations or a tighter numerical tolerance value for $\\epsilon$. We'll compute the rank using the [rank function](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.rank), which is exported by the [Julia LinearAlgebra package](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/).\n",
    "\n",
    "What do we see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a7ff4b-9877-4c9f-a38e-1fbb4953c7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@assert rank(π̄) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d791841-4188-4e31-a67e-dc0dd84473db",
   "metadata": {},
   "source": [
    "### Compute the Markov chain distribution $\\pi$ using the Left Matrix Vector Product\n",
    "Alternatively, we can also compute the stationary distribution $\\bar{\\pi}$ by directly iterating the expression:\n",
    "\n",
    "$$\n",
    "\\pi_{n+1} = \\pi_{n}\\cdot\\mathbf{P}\\quad\\,n=1,2,\\dots\n",
    "$$\n",
    "\n",
    "As $n\\rightarrow\\infty$, i.e., as we perform more iterations, the difference between subsequent iterations becomes small $||\\pi_{n+1}-\\pi_{n}||<\\epsilon$ for a non-periodic Markov chain, where $\\pi_{n}\\rightarrow\\bar{\\pi}$ as $n\\rightarrow\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78fa745-f69f-41bf-9a39-49122dfa41d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0]\n",
      "[0.6, 0.2, 0.2]\n",
      "[0.15, 0.6699999999999999, 0.18]\n",
      "[0.4094999999999999, 0.33049999999999996, 0.26]\n",
      "[0.21877499999999994, 0.533125, 0.2481]\n",
      "[0.3308137499999999, 0.38889124999999997, 0.28029499999999996]\n",
      "[0.2498754374999999, 0.4761398124999999, 0.27398475]\n",
      "[0.2981776593749999, 0.4148050531249999, 0.28701728749999994]\n",
      "[0.26379191484374986, 0.45233497328124994, 0.283873111875]\n",
      "[0.2845905797109374, 0.4262312473203125, 0.2891781729687499]\n",
      "[0.2699682773777342, 0.442360752080078, 0.28767097054218743]\n",
      "[0.2789148651169334, 0.4312433050875194, 0.2898418297955468]\n",
      "[0.27269172630835825, 0.43817033181725473, 0.2891379418743867]\n",
      "[0.2765367854057707, 0.4334325889187073, 0.29003062567552157]\n",
      "[0.2738863926215128, 0.43640565162188016, 0.28970795575660657]\n",
      "[0.2755377106042036, 0.4343855900417952, 0.2900766993540006]\n",
      "[0.27440823955528726, 0.4356609528885528, 0.2899308075561595]\n",
      "[0.275116983710896, 0.43479926042208134, 0.2900837558670222]\n",
      "[0.2746354054387935, 0.43534611336987405, 0.2900184811913318]\n",
      "[0.2749394382938641, 0.43497840219822825, 0.29008215950790706]\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    π₁ = [0.0,1.0,0.0]; # initial state = state 2\n",
    "    direct_state_distribution = Dict{Int,Array{Float64,1}}();\n",
    "    direct_state_distribution[1] = π₁;\n",
    "    for n = 2:number_of_simulation_steps\n",
    "        πᵢ = transpose(π₁)*(P)^(n-1)\n",
    "        direct_state_distribution[n] =  transpose(πᵢ)\n",
    "    end\n",
    "    foreach(i-> println(direct_state_distribution[i]), 1:20);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e8924-3194-4648-9515-e71f1c6a53ec",
   "metadata": {},
   "source": [
    "## Task 3: Compute a sequence of states $s_{i}\\in\\mathcal{S}$ from our Markov model using a categorical distribution\n",
    "In this task, we compute the sequence of states for the three-state [Markov chain model](https://en.wikipedia.org/wiki/Markov_chain). We can obtain the dynamics predicted by the [Markov model](https://en.wikipedia.org/wiki/Markov_model), i.e., the sequence of states and state transitions, by sampling the transition probability matrix $\\mathbf{P}$ directly. \n",
    "\n",
    "Now that we are sure that the transition matrix $\\mathbf{P}$ is properly formulated, let's populate the `hidden_state_probability_dictionary`, which holds the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) modeling the transition probability for each hidden state $s\\in\\mathcal{S}$, i.e., the probability that we transition from state $i$ to state $j$ in the next time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d6ee97a-8b18-4075-a51b-4b7c05f4a820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Categorical{P} where P<:Real} with 3 entries:\n",
       "  2 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.6, 0.2…\n",
       "  3 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.0, 0.3…\n",
       "  1 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.05, 0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_state_probability_dictionary = Dict{Int,Categorical}();\n",
    "for i ∈ 1:number_of_hidden_states\n",
    "    hidden_state_probability_dictionary[i] = Categorical(P[i,:])\n",
    "end\n",
    "hidden_state_probability_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18497dbf-60fd-4fdc-86a3-777e38d418e0",
   "metadata": {},
   "source": [
    "Now, we generate `number_of_simulation_steps` worth of dynamic data by sampling the `hidden_state_probability_dictionary`. We store these simulation results in the `hidden_simulation_dict` dictionary, where the `key` holds the time index and the `value` is the system's state, i.e., $s_{i}\\in\\mathcal{S}$.\n",
    "\n",
    "We start by specifying an initial state `sᵢ = 1`. At each iteration of the loop, we retrieve the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) corresponding to the current state, i.e., the row in the transition matrix $\\mathbf{P}$ corresponding to state $s_{i}$. We generate the state at the next step by drawing a sample using the `rand(...)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3207d76-a6de-46d3-bce6-5ec91e80eaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soln: (t=1,s=1)\n",
      "Soln: (t=2,s=2)\n",
      "Soln: (t=3,s=3)\n",
      "Soln: (t=4,s=3)\n",
      "Soln: (t=5,s=3)\n",
      "Soln: (t=6,s=2)\n",
      "Soln: (t=7,s=2)\n",
      "Soln: (t=8,s=3)\n",
      "Soln: (t=9,s=3)\n",
      "Soln: (t=10,s=2)\n"
     ]
    }
   ],
   "source": [
    "hidden_simulation_dict = let\n",
    "\n",
    "    # initialize -\n",
    "    hidden_simulation_dict = Dict{Int,Int}();\n",
    "    sᵢ = 1; # hardcode the start state: we could draw from the stationary distribution\n",
    "    hidden_simulation_dict[1] = sᵢ;\n",
    "\n",
    "    for i ∈ 2:number_of_simulation_steps\n",
    "\n",
    "        # get the categorical distribution for sᵢ \n",
    "        sᵢ = hidden_state_probability_dictionary[sᵢ] |> d -> rand(d);\n",
    "    \n",
    "        # capture -\n",
    "        hidden_simulation_dict[i] = sᵢ\n",
    "    end\n",
    "    foreach(i -> println(\"Soln: (t=$(i),s=$(hidden_simulation_dict[i]))\"), 1:10) # print first few steps\n",
    "\n",
    "    hidden_simulation_dict; # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8c7ab-ba62-4068-acb9-46585a756afa",
   "metadata": {},
   "source": [
    "### Check: Do we recover the stationary distribution $\\bar{\\pi}$?\n",
    "Just like any dynamic system, e.g., concentration balances in a steady-state reactor, constant flow of liquid through a pipe, or the volume of water in a sink with the faucet on and the drain partially closed, if we wait long enough, a Markov model will approach its stationary distribution $\\bar{\\pi}$.\n",
    "\n",
    "We've generated `number_of_simulation_steps` worth of data from our Markov model. Let's check if the distribution of states from our simulation matches the stationary distribution $\\bar{\\pi}$ that we computed in Task 2.\n",
    "\n",
    "> __What should we expect to see?__ As the number of simulation steps increases, the frequency distribution of states observed in our simulation should approach the stationary distribution $\\bar{\\pi}$. \n",
    "\n",
    "So what do we see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc4a41e-66bb-49e7-819f-b3f1ff87c9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- ------- ------- ----------- -------------\n",
      " \u001b[1m state \u001b[0m \u001b[1m count \u001b[0m \u001b[1m total \u001b[0m \u001b[1m frequency \u001b[0m \u001b[1m probability \u001b[0m\n",
      " \u001b[90m Int64 \u001b[0m \u001b[90m Int64 \u001b[0m \u001b[90m Int64 \u001b[0m \u001b[90m   Float64 \u001b[0m \u001b[90m     Float64 \u001b[0m\n",
      " ------- ------- ------- ----------- -------------\n",
      "      1    2693   10000      0.2693      0.274809\n",
      "      2    4302   10000      0.4302      0.435115\n",
      "      3    3005   10000      0.3005      0.290076\n",
      " ------- ------- ------- ----------- -------------\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    # initialize -\n",
    "    df = DataFrame();\n",
    "   \n",
    "    # count the number of times we visit each state\n",
    "    S = [hidden_simulation_dict[i] for i ∈ 1:number_of_simulation_steps];\n",
    "    NS₁ = findall(x-> x == 1, S) |> length;\n",
    "    NS₂ = findall(x-> x == 2, S) |> length;\n",
    "    NS₃ = findall(x-> x == 3, S) |> length;\n",
    "\n",
    "    # compute the frequency of each state\n",
    "    PS1 = NS₁/number_of_simulation_steps;\n",
    "    PS2 = NS₂/number_of_simulation_steps;\n",
    "    PS3 = NS₃/number_of_simulation_steps;\n",
    "\n",
    "    # Let's make a table -\n",
    "    # state 1\n",
    "    row_df = (\n",
    "        state = 1,\n",
    "        count = NS₁,\n",
    "        total = number_of_simulation_steps,\n",
    "        frequency = PS1,\n",
    "        probability = π̄[1,1]\n",
    "    );\n",
    "    push!(df, row_df);\n",
    "\n",
    "    # state 2:\n",
    "    row_df = (\n",
    "        state = 2,\n",
    "        count = NS₂,\n",
    "        total = number_of_simulation_steps,\n",
    "        frequency = PS2,\n",
    "        probability = π̄[1,2]\n",
    "    );\n",
    "    push!(df, row_df);\n",
    "\n",
    "    # state 3:\n",
    "    row_df = (\n",
    "        state = 3,\n",
    "        count = NS₃,\n",
    "        total = number_of_simulation_steps,\n",
    "        frequency = PS3,\n",
    "        probability = π̄[1,3]\n",
    "    );\n",
    "    push!(df, row_df);\n",
    "\n",
    "\n",
    "    pretty_table(\n",
    "        df;\n",
    "        backend = :text,\n",
    "        table_format = TextTableFormat(borders = text_table_borders__compact)\n",
    "    );\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f7f9d-5242-4b9c-855c-335e6cbd561b",
   "metadata": {},
   "source": [
    "### What happens if we sample $\\bar{\\pi}$ directly?\n",
    "The simulation above tracks the full Markov chain dynamics by sampling the transition matrix $\\mathbf{P}$ step-by-step. But what if we only care about the long-run behavior? We can skip the dynamics entirely and sample $\\bar{\\pi}$ directly. This is faster but loses all information about state transitions over time.\n",
    "\n",
    "Let's create a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) using the stationary probability of our Markov chain with the [Distributions.jl](https://github.com/JuliaStats/Distributions.jl) package and save it in the variable `d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f095b12-c59e-4624-b1e1-77da19c67d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = Categorical(π̄[1,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699869a-4fa4-4c8c-a266-2b7f8a24248f",
   "metadata": {},
   "source": [
    "We generate samples from the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) saved in the distribution `d` using the [rand function](https://docs.julialang.org/en/v1/stdlib/Random/#Base.rand). This allows us to simulate the steady-state behavior of the system encoded by our three-state Markov model. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1923d6-2993-4d15-bdfc-4f7a9c935472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Int64}:\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 2\n",
       " 3\n",
       " 2\n",
       " ⋮\n",
       " 3\n",
       " 1\n",
       " 3\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 3\n",
       " 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand(d,100) # we generate 100 samples from the stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d99c66-0915-41f6-8cfa-11f79567d7cf",
   "metadata": {},
   "source": [
    "### Check: Do we recover the stationary distribution $\\bar{\\pi}$?\n",
    "If the distribution `d` represents the stationary distribution $\\bar{\\pi}$, we should be able to generate many samples and estimate the probability that we are in state `s=1`, `s=2`, or `s=3`. Let's sample the distribution `d` to recover the stationary distribution $\\pi$. \n",
    "\n",
    "We'll compute `number_of_samples` from the distribution `d` and then calculate the frequency of `s = 1`, `s = 2`, and `s = 3` values. These should converge to the stationary probability as the `number_of_samples` becomes large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ba781f-abce-430f-97ad-c8adf29df75c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- ------- ------- ----------- -------------\n",
      " \u001b[1m state \u001b[0m \u001b[1m count \u001b[0m \u001b[1m total \u001b[0m \u001b[1m frequency \u001b[0m \u001b[1m probability \u001b[0m\n",
      " \u001b[90m Int64 \u001b[0m \u001b[90m Int64 \u001b[0m \u001b[90m Int64 \u001b[0m \u001b[90m   Float64 \u001b[0m \u001b[90m     Float64 \u001b[0m\n",
      " ------- ------- ------- ----------- -------------\n",
      "      1    2666   10000      0.2666      0.274809\n",
      "      2    4347   10000      0.4347      0.435115\n",
      "      3    2987   10000      0.2987      0.290076\n",
      " ------- ------- ------- ----------- -------------\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    # initialize -\n",
    "    df = DataFrame();\n",
    "    samples = rand(d, number_of_samples);\n",
    "\n",
    "    # compute the counts -\n",
    "    N₁ = findall(x-> x == 1, samples) |> length;\n",
    "    N₂ = findall(x-> x == 2, samples) |> length;\n",
    "    N₃ = findall(x-> x == 3, samples) |> length;\n",
    "\n",
    "    # compute the frequencies -\n",
    "    f₁ = N₁/number_of_samples;\n",
    "    f₂ = N₂/number_of_samples;\n",
    "    f₃ = N₃/number_of_samples;\n",
    "\n",
    "    # Let's make a table -\n",
    "    # state 1\n",
    "    row_df = (\n",
    "        state = 1,\n",
    "        count = N₁,\n",
    "        total = number_of_simulation_steps,\n",
    "        frequency = f₁,\n",
    "        probability = π̄[1,1]\n",
    "    );\n",
    "    push!(df, row_df);\n",
    "\n",
    "    # state 2:\n",
    "    row_df = (\n",
    "        state = 2,\n",
    "        count = N₂,\n",
    "        total = number_of_simulation_steps,\n",
    "        frequency = f₂,\n",
    "        probability = π̄[1,2]\n",
    "    );\n",
    "    push!(df, row_df);\n",
    "\n",
    "    # state 3:\n",
    "    row_df = (\n",
    "        state = 3,\n",
    "        count = N₃,\n",
    "        total = number_of_simulation_steps,\n",
    "        frequency = f₃,\n",
    "        probability = π̄[1,3]\n",
    "    );\n",
    "    push!(df, row_df);\n",
    "\n",
    "\n",
    "    pretty_table(\n",
    "        df;\n",
    "        backend = :text,\n",
    "        table_format = TextTableFormat(borders = text_table_borders__compact)\n",
    "    );\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f70cd",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca463ddb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this example, we explored the fundamental properties of Markov models by constructing a three-state Markov chain, computing its stationary distribution through matrix iteration, and validating theoretical predictions through simulation.\n",
    "\n",
    "> __Key Takeaways:__\n",
    "> \n",
    "> * **Transition matrix structure and properties:** We constructed a 3×3 transition matrix P satisfying the row-stochastic property and verified that each row sums to one. The full rank of the transition matrix ensures that all states are accessible, which is necessary for the existence of a unique stationary distribution.\n",
    "> * **Stationary distribution convergence:** We computed the stationary distribution π by iteratively raising the transition matrix to successive powers until convergence (when ||P^(k+1) - P^k|| < ε). The resulting matrix converged to rank-one, where every row contains identical probability values representing the stationary distribution, confirming the theoretical prediction for non-periodic Markov chains.\n",
    "> * **Simulation validates theoretical predictions:** We generated 10,000-step state sequences by sampling categorical distributions based on transition probabilities and demonstrated that empirical state frequencies converged to the theoretical stationary distribution. Direct sampling from the stationary distribution produced identical frequency distributions but eliminated temporal dynamics, illustrating the trade-off between steady-state and transient behavior analysis.\n",
    "\n",
    "The Markov model framework provides a powerful mathematical tool for modeling stochastic systems, with applications ranging from natural language processing to financial modeling and biological sequence analysis.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.1",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
