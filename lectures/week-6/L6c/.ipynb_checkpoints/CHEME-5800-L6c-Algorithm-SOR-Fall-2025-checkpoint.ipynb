{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f3d235-5633-44da-ba66-aef39d6524b6",
   "metadata": {},
   "source": [
    "# Successive Over-Relaxation (SOR) Method\n",
    "The Successive Over-Relaxation (SOR) method is a variant of the Gauss-Seidel method that introduces a relaxation factor $\\omega \\in (0, 2)$ to accelerate convergence. The relaxation factor $\\omega$ is a parameter that can be tuned to improve the convergence rate of the method. \n",
    "\n",
    "For the SOR method, we can still split the system matrix $\\mathbf{A} = \\mathbf{M} - \\mathbf{N}$ where:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{M}_{\\omega} &= \\frac{1}{\\omega}\\;\\left(\\mathbf{D} + \\omega\\;\\mathbf{L}\\right)\\\\\n",
    "\\mathbf{N}_{\\omega} &= \\left(\\frac{1}{\\omega} - 1\\right)\\;\\mathbf{D} - \\mathbf{U}\n",
    "\\end{align*}\n",
    "$$\n",
    "which leads to the update direction expression for the SOR method:\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathbf{d}^{(k)} = \\omega\\,(\\mathbf{D}+\\omega\\,\\mathbf{L})^{-1}\\,\\underbrace{(\\mathbf{b} - \\mathbf{A}\\mathbf{x}^{(k)})}_{\\text{residual}\\;\\mathbf{r}^{(k)}}\n",
    "}\n",
    "$$\n",
    "Let's sketch out the SOR method.\n",
    "\n",
    "__Initialize__: Given the system matrix $\\mathbf{A}\\in\\mathbb{R}^{n \\times n}$ and the right-hand side vector $\\mathbf{b}\\in\\mathbb{R}^{n}$, we start with an initial guess for the solution vector $\\mathbf{x}^{(0)}\\in\\mathbb{R}^{n}$. This guess can be a zero vector or any other reasonable approximation. Set $\\texttt{converged} \\gets \\texttt{false}$ and the iteration counter $k\\gets0$. Specify a convergence criterion, such as a tolerance level $\\epsilon > 0$, and a maximum number of iterations $\\texttt{max\\_iter}$. Choose a relaxation factor $\\omega \\in (0, 2)$.\n",
    "\n",
    "While not $\\texttt{converged}$ __do__:\n",
    "1. Calculate the residual vector $\\mathbf{r}^{(k)} \\gets \\mathbf{b} - \\mathbf{A}\\mathbf{x}^{(k)}$.\n",
    "2. Check for convergence:\n",
    "   - If $\\|\\mathbf{r}^{(k)}\\|_{2} < \\epsilon$, __then__: set $\\texttt{converged} \\gets \\texttt{true}$. \n",
    "   - If $k \\geq \\texttt{max\\_iter}$, __then__: set $\\texttt{converged} \\gets \\texttt{true}$, and print a __warning__ that the method did not converge.\n",
    "3. Calculate the update direction: $\\mathbf{d}^{(k)} \\gets \\omega\\;(\\mathbf{D} + \\omega\\,\\mathbf{L})^{-1}\\;\\mathbf{r}^{(k)}$.\n",
    "4. Update the solution vector: $\\mathbf{x}^{(k+1)} \\gets \\mathbf{x}^{(k)} + \\mathbf{d}^{(k)}$.\n",
    "5. Increment the iteration counter: $k \\gets k + 1$.\n",
    "\n",
    "The iteration matrix for the SOR method is given by: $\\mathbf{G}_{\\omega} = (\\mathbf{D}+\\omega\\,\\mathbf{L})^{-1}\\,\\bigl((1-\\omega)\\;\\mathbf{D} - \\omega\\,\\mathbf{U}\\bigr)$. Thus, the SOR method converges from any initial guess if and only if $\\rho(\\mathbf{G}_{\\omega}) < 1$, where $\\rho(\\mathbf{G}_{\\omega})$ is the spectral radius of the iteration matrix $\\mathbf{G}_{\\omega}$.\n",
    "\n",
    "### How to choose $\\omega$?\n",
    "Choosing the relaxation factor $\\omega$ is important for the performance of the SOR method. There are many heuristics and methods to choose $\\omega$, but a common approach is to use the following expression:\n",
    "$$\n",
    "\\omega \\simeq \\frac{2}{1 + \\sqrt{1 - \\rho(\\mathbf{G}_{J})^2}}\n",
    "$$\n",
    "where $\\rho(\\mathbf{G}_{J})$ is the spectral radius of the iteration matrix for the Jacobi method. The origin of this expression comes from tuning $\\omega$ so that the fastest- and slowest-decaying error components shrink at the same rate, which minimizes the worst-case convergence factor. There is more to that story, but we will skip the details here!\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
